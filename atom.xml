<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Rocky1ee的博客</title>
  <icon>https://www.gravatar.com/avatar/cdf2628d43f941c34796949e0857e3a5</icon>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="//Rocky1ee.github.io/"/>
  <updated>2019-12-09T12:42:12.924Z</updated>
  <id>//Rocky1ee.github.io/</id>
  
  <author>
    <name>Rocky1ee</name>
    <email>666@qq.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title></title>
    <link href="//Rocky1ee.github.io/2019/12/09/%E8%92%99%E7%89%B9%E5%8D%A1%E7%BD%97%E7%AE%97%E6%B3%95/"/>
    <id>//Rocky1ee.github.io/2019/12/09/蒙特卡罗算法/</id>
    <published>2019-12-09T05:44:22.908Z</published>
    <updated>2019-12-09T12:42:12.924Z</updated>
    
    <content type="html"><![CDATA[<p>蒙特卡罗算法：采样越多，越<strong>近似</strong>最优解；用有限随机数去计算估计值.</p><p>举个例子，假如筐里有100个苹果，让我每次闭眼拿1个，挑出最大的。于是我随机拿1个，再随机拿1个跟它比，留下大的，再随机拿1个……我每拿一次，留下的苹果都至少不比上次的小。拿的次数越多，挑出的苹果就越大，但我除非拿100次，否则无法肯定挑出了最大的。这个挑苹果的算法，就属于蒙特卡罗算法——<strong>尽量找好的，但不保证是最好的</strong>。</p><div class="figure"><img src="/Assets/BlogImg/圆周率估计.gif" alt="Monte Carlo Method"><p class="caption">Monte Carlo Method</p></div><p>使用蒙特卡洛方法估算π值. 放置30000个随机点后,π的估算值与真实值相差0.07%.</p><p>这张图其实很简单, 就像我们玩飞镖一样, 随机地在一个方形平面上投掷30000个飞镖, 事先我们并不知道圆周率π的值究竟是多少, 但是我们知道这里有1/4的圆, 于是我们把红色面积上的点数<span class="math inline">\(m\)</span>, 和蓝色面积上的点数<span class="math inline">\(n\)</span>, 以及圆周率<span class="math inline">\(π\)</span>的关系, 可以写出一个约等于的式子: <span class="math display">\[π ≈ 4m/(n+m)\]</span> 随着<span class="math inline">\(m+n\)</span>的投射点的逐渐增加, <span class="math inline">\(π\)</span>值的计算也越来越精确, 最后我们就估计出一个不错的比较精确的<span class="math inline">\(π\)</span>值啦</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;蒙特卡罗算法：采样越多，越&lt;strong&gt;近似&lt;/strong&gt;最优解；用有限随机数去计算估计值.&lt;/p&gt;
&lt;p&gt;举个例子，假如筐里有100个苹果，让我每次闭眼拿1个，挑出最大的。于是我随机拿1个，再随机拿1个跟它比，留下大的，再随机拿1个……我每拿一次，留下的苹果都至少
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>模拟退火算法</title>
    <link href="//Rocky1ee.github.io/2019/09/06/%E6%A8%A1%E6%8B%9F%E9%80%80%E7%81%AB%E7%AE%97%E6%B3%95SA/"/>
    <id>//Rocky1ee.github.io/2019/09/06/模拟退火算法SA/</id>
    <published>2019-09-06T11:56:36.000Z</published>
    <updated>2019-12-10T07:43:48.033Z</updated>
    
    <content type="html"><![CDATA[<p>模拟退火算法(Simulated Annealing)：采用类似于物理退火的过程，先在一个高温状态下（相当于算法随机搜索），然后逐渐退火，在每个温度下（相当于算法的每一次状态转移）徐徐冷却（相当于算法局部搜索），最终达到物理基态（相当于算法找到最优解）。</p><h1 id="算法思想">算法思想</h1><h2 id="爬山算法">爬山算法</h2><p><strong>爬山算法</strong>是一种简单的<strong>贪心搜索算法</strong>，它每次都<strong>鼠目寸光</strong>地从当前解临近的解空间中选择一个更优解代替当前解，直到得到一个局部最优解。</p><p>如图1所示：假设C点为当前解，爬山算法搜索到A点这个局部最优解后就会停止搜索，因为在A点无论向那个方向小幅度移动都不能得到更优的解。因此，爬山算法只能搜索到局部最优值，而不一定能搜索到全局最优解。</p><div class="figure"><img src="/Assets/BlogImg/SA.jpg" alt="图 1"><p class="caption">图 1</p></div><h2 id="模拟退火算法">模拟退火算法</h2><p>模拟退火算法其实也是一种贪心算法，但是它的搜索过程引入了随机因素。模拟退火算法<strong>以一定的概率</strong>来接受一个比当前解要差的解，因此<strong>有可能</strong>会跳出这个局部的最优解，达到全局的最优解。</p><p>以图1为例，模拟退火算法在搜索到局部最优解A后，会<strong>以一定的概率</strong>向E的移动。可能经过几次这样的不是局部最优的移动后会到达D点，于是就跳出了局部最大值A。模拟退火算法是一种随机算法，并不一定能找到全局的最优解，但可以比较快的找到问题的近似最优解。</p><a id="more"></a><h1 id="算法流程">算法流程</h1><p><img src="/Assets/BlogImg/SA2.png" alt="The process of SA" style="zoom:80%;"></p><h2 id="初始化">初始化</h2><p>模拟退火时需设定三个参数：一个比较大初始温度<span class="math inline">\(T_0\)</span> ，降温系数<span class="math inline">\(d\)</span> 非常接近但小于<span class="math inline">\(1\)</span>，终止温度 <span class="math inline">\(T_k\)</span>是一个接近<span class="math inline">\(0\)</span>的正数。</p><h2 id="metropolis准则">Metropolis准则</h2>解的替换按照Metropolis准则进行，假设前一状态为 <span class="math inline">\(f(x_n)\)</span>，系统受到一定扰动，状态变为 <span class="math inline">\(f(x_{n+1})\)</span>，相应地，系统能量由 <span class="math inline">\(E(x_n)\)</span> 变为 <span class="math inline">\(E(x_{n+1})\)</span>。 定义系统由 <span class="math inline">\(f(x_n)\)</span> 变为$f(x_{n+1}) $的接收概率为 <span class="math inline">\(p\)</span>（probability of acceptance）： $$<span class="math display">\[\begin{equation}p=\begin{cases}1, \quad &amp;if \quad E(x_{n+1})&lt;E(x_n)\\e^{-\frac{E(x_{n+1})-E(x_n)}{T}} \quad &amp;if \quad E(x_{n+1})\geq E(x_n)\end{cases}\end{equation}\]</span><p>$$</p><p>通俗解释为：</p><ol style="list-style-type: decimal"><li>在高温下可接受与当前状态能量差较大的新状态；</li><li>在低温下基本只接受与当前能量差较小的新状态；</li><li>当温度趋于零时，就不能接受比当前状态能量高的新状态。</li></ol><p>随着温度的降低，对随机性的接受度降低。</p><h2 id="迭代更新">迭代更新</h2><p>首先让温度 <span class="math inline">\(T=T_0\)</span>，然后按照上述Metroplis准则对解进行更新，再让<span class="math inline">\(T=d \times T\)</span>。当<span class="math inline">\(T&lt;T_k\)</span>时模拟退火过程结束，当前最优解即为最终的最优解。</p><p>直观表示如下图：随着温度的降低，跳跃越来越不随机，最优解也越来越稳定。</p><div class="figure"><img src="/Assets/BlogImg/SA3.gif" alt="退火算法求解过程"><p class="caption">退火算法求解过程</p></div><h1 id="算法实例">算法实例</h1><h1 id="references">references</h1><p>OI Wiki 习题https://oi-wiki.org/misc/simulated-annealing/</p><p>科学网 http://blog.sciencenet.cn/blog-1813407-893984.html</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;模拟退火算法(Simulated Annealing)：采用类似于物理退火的过程，先在一个高温状态下（相当于算法随机搜索），然后逐渐退火，在每个温度下（相当于算法的每一次状态转移）徐徐冷却（相当于算法局部搜索），最终达到物理基态（相当于算法找到最优解）。&lt;/p&gt;
&lt;h1 id=&quot;算法思想&quot;&gt;算法思想&lt;/h1&gt;
&lt;h2 id=&quot;爬山算法&quot;&gt;爬山算法&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;爬山算法&lt;/strong&gt;是一种简单的&lt;strong&gt;贪心搜索算法&lt;/strong&gt;，它每次都&lt;strong&gt;鼠目寸光&lt;/strong&gt;地从当前解临近的解空间中选择一个更优解代替当前解，直到得到一个局部最优解。&lt;/p&gt;
&lt;p&gt;如图1所示：假设C点为当前解，爬山算法搜索到A点这个局部最优解后就会停止搜索，因为在A点无论向那个方向小幅度移动都不能得到更优的解。因此，爬山算法只能搜索到局部最优值，而不一定能搜索到全局最优解。&lt;/p&gt;
&lt;div class=&quot;figure&quot;&gt;
&lt;img src=&quot;/Assets/BlogImg/SA.jpg&quot; alt=&quot;图 1&quot;&gt;
&lt;p class=&quot;caption&quot;&gt;图 1&lt;/p&gt;
&lt;/div&gt;
&lt;h2 id=&quot;模拟退火算法&quot;&gt;模拟退火算法&lt;/h2&gt;
&lt;p&gt;模拟退火算法其实也是一种贪心算法，但是它的搜索过程引入了随机因素。模拟退火算法&lt;strong&gt;以一定的概率&lt;/strong&gt;来接受一个比当前解要差的解，因此&lt;strong&gt;有可能&lt;/strong&gt;会跳出这个局部的最优解，达到全局的最优解。&lt;/p&gt;
&lt;p&gt;以图1为例，模拟退火算法在搜索到局部最优解A后，会&lt;strong&gt;以一定的概率&lt;/strong&gt;向E的移动。可能经过几次这样的不是局部最优的移动后会到达D点，于是就跳出了局部最大值A。模拟退火算法是一种随机算法，并不一定能找到全局的最优解，但可以比较快的找到问题的近似最优解。&lt;/p&gt;
    
    </summary>
    
      <category term="算法学习" scheme="//Rocky1ee.github.io/categories/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="模拟退火算法" scheme="//Rocky1ee.github.io/tags/%E6%A8%A1%E6%8B%9F%E9%80%80%E7%81%AB%E7%AE%97%E6%B3%95/"/>
    
      <category term="智能算法" scheme="//Rocky1ee.github.io/tags/%E6%99%BA%E8%83%BD%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>遗传算法</title>
    <link href="//Rocky1ee.github.io/2019/09/04/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95GA/"/>
    <id>//Rocky1ee.github.io/2019/09/04/遗传算法GA/</id>
    <published>2019-09-04T09:56:36.000Z</published>
    <updated>2019-12-10T07:45:30.478Z</updated>
    
    <content type="html"><![CDATA[<p>遗传算法（Genetic Algorithm）</p><h1 id="算法背景">算法背景</h1><p><strong>种群(Population)</strong>：生物的进化以群体的形式进行，这样的一个群体称为种群。</p><p><strong>个体</strong>：组成种群的单个生物。</p><p><strong>染色体 ( Chromosome )</strong> ：包含一组的基因。</p><p><strong>基因 ( Gene )</strong> ：一个遗传因子。</p><p><strong>生存竞争，适者生存</strong>：对环境适应度高的、优良的个体参与繁殖的机会比较多，后代就会越来越多。适应度低的个体参与繁殖的机会比较少，后代就会越来越少。</p><p><strong>选择</strong>：根据相应策略选择父母染色体对进行繁殖。</p><p><strong>交叉</strong>：将父母双方各一部分的基因进行组合形成子代染色体。</p><p><strong>变异</strong>：子代染色体有一定的概率发生基因变异。</p><p>简单说来就是：选择优良父代进行繁殖，期间会发生基因交叉( Crossover ) ，基因突变 ( Mutation ) ，适应度( Fitness )低的个体会被逐步淘汰，而适应度高的个体会越来越多。那么经过N代的自然选择后，保存下来的个体都是适应度很高的，其中很可能包含史上产生的适应度最高的个体。</p><h1 id="算法流程">算法流程</h1><h2 id="总体流程">总体流程</h2><div class="figure"><img src="/Assets/BlogImg/GA1.jpg" alt="The process of GA"><p class="caption">The process of GA</p></div><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">begin</span><br><span class="line">       initialize P(0);      </span><br><span class="line">       t = 0;             //t是进化的代数，一代、二代、三代...</span><br><span class="line"></span><br><span class="line">       while(t &lt;= T) do</span><br><span class="line">              for i = 1 to M  do     //M是初始种群的个体数</span><br><span class="line">                     Evaluate fitness of P(t);  //计算P（t）中各个个体的适应度</span><br><span class="line">              end for</span><br><span class="line"></span><br><span class="line">              for i = 1 to M  do</span><br><span class="line">                     Select operation to P(t);  //将选择算子作用于群体</span><br><span class="line">              end for</span><br><span class="line"></span><br><span class="line">              for i = 1 to M/2  do</span><br><span class="line">                     Crossover operation to P(t); //将交叉算子作用于群体</span><br><span class="line">              end for</span><br><span class="line"></span><br><span class="line">              for i = 1 to M  do</span><br><span class="line">                     Mutation operation to P(t);  //将变异算子作用于群体</span><br><span class="line">              end for</span><br><span class="line"></span><br><span class="line">              for i = 1 to M  do</span><br><span class="line">                     P(t+1) = P(t);      //得到下一代群体P（t + 1）</span><br><span class="line">              end for</span><br><span class="line">              </span><br><span class="line">              t = t + 1;      //终止条件判断  t≦T：t← t+1 转到步骤2</span><br><span class="line"></span><br><span class="line">       end while</span><br><span class="line">end</span><br></pre></td></tr></table></figure><h2 id="编码">编码</h2><p>遗传算法需要将问题的解(个体)编码成字符串的形式。最简单的一种编码方式是二进制编码，</p><p>即<span class="math inline">\(24=11000\)</span>。</p><h2 id="适应度计算">适应度计算</h2><p>适应度函数 ( Fitness Function )：用于评价染色体的适应度，用<span class="math inline">\(f(x)\)</span>表示。<strong>适应度函数</strong>与<strong>目标函数</strong>是正相关的，可对目标函数作一些变形来得到适应度函数。有时需要区分染色体的适应度函数与问题的目标函数。例如：0-1背包问题的目标函数是所取得物品价值，但将物品价值作为染色体的适应度函数可能并不一定适合。</p><h2 id="选择">选择</h2><p>使用选择运算子对个体进行优胜劣汰操作。适应度高的个体被遗传到下一代群体中的概率大；适应度低的个体，被遗传到下一代群体中的概率小。目标就是从父代群体中选取优个体，遗传到下一代群体。</p><p>常用算法为轮盘赌法： <span class="math display">\[P(x_i)=\frac{f(x_i)}{\sum\limits_{j=1}^Nf(x_j)}\qquad(1)\]</span> <span class="math inline">\(x_i\)</span>:个体<span class="math inline">\(i，i \in[1,N]\)</span>,<span class="math inline">\(f()\)</span>:适应度函数,<span class="math inline">\(P(x_i)\)</span>:选择个体<span class="math inline">\(i\)</span>的概率。 <span class="math display">\[q_i = \sum\limits_{j=1}^iP(x_j)\qquad (2)\]</span> <span class="math inline">\(q_i\)</span>为累积概率。</p><div class="figure"><img src="/Assets/BlogImg/轮盘赌选择法.jpeg" alt="轮盘赌法"><p class="caption">轮盘赌法</p></div><p>生成随机数<span class="math inline">\(r_k \in[0,1],k =1,2,3...N\)</span>,<span class="math inline">\(N\)</span>为选择个体总数。假设<span class="math inline">\(r_1=0.4\)</span>,则选择<span class="math inline">\(个体3\)</span>,即选择<span class="math inline">\(q_i \geq r_1\)</span>的第首个个体。</p><h2 id="交叉">交叉</h2><p>染色体交叉是以一定的概率发生的，这个概率记为$P_c $。交叉的方法有很多种，这里用的是单点交叉</p><p>交叉前：</p><p>00000|<strong>011100000000</strong>|10000</p><p>11100|<strong>000001111110</strong>|00101</p><p>交叉后：</p><p>00000|<strong>000001111110</strong>|10000</p><p>11100|<strong>011100000000</strong>|00101</p><h2 id="变异">变异</h2><p>在繁殖过程，新产生的染色体中的基因会以一定的概率出错，称为变异。变异发生的概率记为&amp;P_m&amp;</p><p>变异前：</p><p>000001110000<strong>0</strong>00010000</p><p>变异后：</p><p>000001110000<strong>1</strong>00010000</p><h1 id="算法实例">算法实例</h1><p>已知<span class="math inline">\(x\)</span>为整数，利用遗传算法求函数<span class="math inline">\(y=x^2\)</span>区间<span class="math inline">\([0, 31]\)</span>上的的最大值。</p><h2 id="初始化">初始化</h2><p>将种群规模设定为<span class="math inline">\(M=4\)</span>；用5位二进制数编码染色体；取下列个体组成初始种群<span class="math inline">\(S_1\)</span> <span class="math display">\[s_1= 13 (01101),  s_2= 24 (11000)\\s_3= 8 (01000),    s_4= 19 (10011）\]</span></p><h2 id="适应度计算-1">适应度计算</h2><p>适应度函数定义为<span class="math inline">\(f(x)=x^2\)</span>,由此计算各染色体的适应度： <span class="math display">\[\begin{split}&amp;f (s_1) = f(13) = 13^2 = 169\\&amp;f (s_2) = f(24) = 24^2 = 576\\&amp;f (s_3) = f(8) = 8^2 = 64\\&amp;f (s_4) = f(19) = 19^2 = 361\end{split}\]</span> ## 选择</p><p>再由公式(1)计算<span class="math inline">\(S_1\)</span>中各个体的选择概率： <span class="math display">\[\begin{split}&amp;P(s_1) = P(13) = 0.14\\&amp;P(s_2) = P(24) = 0.49\\&amp;P(s_3) = P(8) = 0.06\\&amp;P(s_4) = P(19) = 0.31\end{split}\]</span> 再由公式(2)计算<span class="math inline">\(S_1\)</span>中各个体的累计概率： <span class="math display">\[\begin{split}&amp;q(s_1) = q(13) = 0.14\\&amp;q(s_2) = q(24) = 0.63\\&amp;q(s_3) = q(8) = 0.69\\&amp;q(s_4) = q(19) = 1\end{split}\]</span> 假设从<span class="math inline">\([0,1]\)</span>中产生的<span class="math inline">\(N=4\)</span>个随机数如下： <span class="math display">\[\begin{split}&amp;r1 = 0.450126,\\     &amp;r2 = 0.110347\\&amp;r3 = 0.572496, \\    &amp;r4 = 0.98503\end{split}\]</span> 选择结果为：</p><table><thead><tr class="header"><th>个体</th><th>染色体</th><th>适应度</th><th>选择概率</th><th>累积概率</th><th>选择次数</th></tr></thead><tbody><tr class="odd"><td>13</td><td><span class="math inline">\(s_1=01101\)</span></td><td>169</td><td>0.14</td><td>0.14</td><td>1</td></tr><tr class="even"><td>24</td><td><span class="math inline">\(s_2=11000\)</span></td><td>576</td><td>0.49</td><td>0.63</td><td>2</td></tr><tr class="odd"><td>8</td><td><span class="math inline">\(s_3=01000\)</span></td><td>64</td><td>0.06</td><td>0.69</td><td>0</td></tr><tr class="even"><td>19</td><td><span class="math inline">\(s_4=10011\)</span></td><td>361</td><td>0.31</td><td>1</td><td>1</td></tr></tbody></table><h2 id="交叉-1">交叉</h2><p>设交叉率<span class="math inline">\(p_c\)</span>=100%，即<span class="math inline">\(S_1\)</span>中的全体染色体都参加交叉运算,交叉点位: | 。 设<span class="math inline">\(s_1’与s_2’\)</span>配对，<span class="math inline">\(s_3’与s_4’\)</span>配对。 <span class="math display">\[s_1’ =110|00（24）,  s_2’ =011|01（13）s_3’ =110|00（24）,  s_4’ =100|11（19）\]</span> 分别交换后两位基因，得新染色体： <span class="math display">\[s_1’’=11001（25）,  s_2’’=01100（12）s_3’’=11011（27）,  s_4’’=10000（16）\]</span></p><h2 id="变异-1">变异</h2><p>设变异率<span class="math inline">\(p_m=0.001\)</span>。这样，群体<span class="math inline">\(S1\)</span>中共有<span class="math inline">\(5×4×0.001=0.02\)</span>位基因可以变异。<span class="math inline">\(0.02\)</span>位显然不足1位，所以本轮遗传操作不做变异。</p><p>于是，得到第二代种群S2： <span class="math display">\[s_1=11001（25）,  s_2=01100（12）s_3=11011（27）,  s_4=10000（16）\]</span></p><h2 id="迭代更替">迭代更替</h2><table><thead><tr class="header"><th>个体</th><th>染色体</th><th>适应度</th><th>选择概率</th><th>累积概率</th><th>选择次数</th></tr></thead><tbody><tr class="odd"><td>25</td><td><span class="math inline">\(s_1=11001\)</span></td><td>625</td><td>0.36</td><td>0.36</td><td>1</td></tr><tr class="even"><td>12</td><td><span class="math inline">\(s_2=01100\)</span></td><td>144</td><td>0.07</td><td>0.44</td><td>0</td></tr><tr class="odd"><td>27</td><td><span class="math inline">\(s_3=11011\)</span></td><td>729</td><td>0.41</td><td>0.85</td><td>2</td></tr><tr class="even"><td>256</td><td><span class="math inline">\(s_4=10000\)</span></td><td>256</td><td>0.15</td><td>1.00</td><td>1</td></tr></tbody></table><p>假设这一轮遗传操作中，种群S2中的4个染色体都被选中，则得到群体： <span class="math display">\[ s_1’=11|001（25）,  s_2’=11|011（27）， s_3’=11|011（27）,  s_4’= 10|000（16）\]</span> 做交叉运算，让s1’与s2’，s3’与s4’ 分别交叉，得 <span class="math display">\[s1’’=11011（27）,    s2’’ = 11001（25）,  s3’’ =11000（24）,   s4’’ = 10011（19）\]</span> 这一轮仍然不会发生变异。 于是，得第三代种群S3： <span class="math display">\[s1=11011（27）,    s2 = 11001（25）,  s3 =11000（24）,   s4= 10011（19）\]</span> 迭代到第5代可以得到最优解<span class="math inline">\(s^*=11111(31),f(s^*)=961\)</span>。</p><h2 id="结束">结束</h2><p>按照以上流程不断迭代更替直到迭代次数超出预设值或目标函数的最优值不再变化。</p><h1 id="references">references</h1><p>JULY大神 https://blog.csdn.net/v_JULY_v/article/details/6132775</p><p>Michael翔 https://michael728.github.io/2015/12/24/algorithm-GA-basic/</p><!--more-->]]></content>
    
    <summary type="html">
    
      &lt;p&gt;遗传算法（Genetic Algorithm）&lt;/p&gt;
&lt;h1 id=&quot;算法背景&quot;&gt;算法背景&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;种群(Population)&lt;/strong&gt;：生物的进化以群体的形式进行，这样的一个群体称为种群。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;个体&lt;/strong&gt;：组成种群的单个生物。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;染色体 ( Chromosome )&lt;/strong&gt; ：包含一组的基因。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;基因 ( Gene )&lt;/strong&gt; ：一个遗传因子。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;生存竞争，适者生存&lt;/strong&gt;：对环境适应度高的、优良的个体参与繁殖的机会比较多，后代就会越来越多。适应度低的个体参与繁殖的机会比较少，后代就会越来越少。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;选择&lt;/strong&gt;：根据相应策略选择父母染色体对进行繁殖。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;交叉&lt;/strong&gt;：将父母双方各一部分的基因进行组合形成子代染色体。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;变异&lt;/strong&gt;：子代染色体有一定的概率发生基因变异。&lt;/p&gt;
&lt;p&gt;简单说来就是：选择优良父代进行繁殖，期间会发生基因交叉( Crossover ) ，基因突变 ( Mutation ) ，适应度( Fitness )低的个体会被逐步淘汰，而适应度高的个体会越来越多。那么经过N代的自然选择后，保存下来的个体都是适应度很高的，其中很可能包含史上产生的适应度最高的个体。&lt;/p&gt;
&lt;h1 id=&quot;算法流程&quot;&gt;算法流程&lt;/h1&gt;
&lt;h2 id=&quot;总体流程&quot;&gt;总体流程&lt;/h2&gt;
&lt;div class=&quot;figure&quot;&gt;
&lt;img src=&quot;/Assets/BlogImg/GA1.jpg&quot; alt=&quot;The process of GA&quot;&gt;
&lt;p class=&quot;caption&quot;&gt;The process of GA&lt;/p&gt;
&lt;/div&gt;
    
    </summary>
    
      <category term="算法学习" scheme="//Rocky1ee.github.io/categories/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="智能算法" scheme="//Rocky1ee.github.io/tags/%E6%99%BA%E8%83%BD%E7%AE%97%E6%B3%95/"/>
    
      <category term="进化算法" scheme="//Rocky1ee.github.io/tags/%E8%BF%9B%E5%8C%96%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>简化粒子群</title>
    <link href="//Rocky1ee.github.io/2019/09/03/%E7%AE%80%E5%8C%96%E7%BE%A4%E4%BC%98%E5%8C%96SSO/"/>
    <id>//Rocky1ee.github.io/2019/09/03/简化群优化SSO/</id>
    <published>2019-09-03T07:56:36.000Z</published>
    <updated>2019-12-10T05:54:19.335Z</updated>
    
    <content type="html"><![CDATA[<h1 id="abstract">Abstract</h1><p>Swarm-based optimization tend to suffer from premature convergence in the high dimensional problem space. thus，proposing simplified swarm optimization (SSO) algorithm to overcome the above convergence problem by incorporating it with the new <strong>local search strategy</strong> named ELS(Exchange Local Search).</p><h1 id="introduction">Introduction</h1><p>The ELS strategy is introduced to find a better solution from the neighbourhood of the current solution which is produced by SSO. It allows the particles to better explore the search space, and preserves swarm diversity which is important in preventing premature convergence of the particles.</p><a id="more"></a><h1 id="particle-swarm-optimization-and-simplified-swarm-optimization.">Particle Swarm Optimization and Simplified Swarm Optimization.</h1><h2 id="pso">PSO</h2><p><span class="math display">\[v_{id}^t = \omega\cdot v_{id}^{t-1}+c_1\cdot rand_1\cdot (p_{id}-x_{id}^{t-1})+c_2\cdot rand_2\cdot(p_{gd}-x_{id}^{t-1}) \quad (1)\]</span></p><p><span class="math display">\[x_{id}^t = x_{id}^{t-1}+v_{id}^t \quad (2)\]</span></p><p>The algorithm of the standard PSO is presented as follows:</p><ol style="list-style-type: decimal"><li>Initialize a population of particles with random positions and velocities.</li><li>Evaluate the fitness value of each particle in the population.</li><li>Get the <span class="math inline">\(pbest\)</span> value. If the fitness value of the particle <span class="math inline">\(i\)</span> is better than its <span class="math inline">\(pbest\)</span> fitness value, and then set the fitness value as a new <span class="math inline">\(pbest\)</span> of particle <span class="math inline">\(i\)</span>.</li><li>Get the <span class="math inline">\(gbest\)</span> value. If any <span class="math inline">\(pbest\)</span> is updated and it is better than the current <span class="math inline">\(gbest\)</span>, and then set <span class="math inline">\(gbest\)</span> to the current <span class="math inline">\(pbest\)</span> value of particle <span class="math inline">\(i\)</span>.</li><li>Update particle’s velocity and position according to (1) and (2).</li><li>Stop iteration if the best fitness value or the maximum generation is met; otherwise go back to step 2.</li></ol><h2 id="sso">SSO</h2><p>In every generation, the particle’s position value in each dimension will be kept or be updated by its <span class="math inline">\(pbest\)</span> value or by the <span class="math inline">\(gbest\)</span> value or be replaced by new random value according to this procedure. <span class="math display">\[x_{id} = \begin{cases}x_{id}^{t-1},\quad if\quad rand() \in[0,C_\omega]&amp;\\p_{id}^{t-1},\quad if\quad rand() \in[C_\omega,C_p]&amp;\\g_{id}^{t-1},\quad if\quad rand() \in[C_p,C_g]&amp;\\x ,\qquad if\quad rand()\in[C_g,1]&amp;\\\end{cases}\quad (3)\]</span> <span class="math inline">\(C_w\)</span> , <span class="math inline">\(C_p\)</span> and <span class="math inline">\(C_g\)</span> are three predetermined positive constants with <span class="math inline">\(C_w &lt; C_p &lt; C_g\)</span> .</p><div class="figure"><img src="/Assets/BlogImg/SSO1.png" alt="Flowchart of SSO algorithm"><p class="caption">Flowchart of SSO algorithm</p></div><p><strong>根据随机概率对粒子的位置进行更新。从而增强模型的随机性，防止提前收敛。</strong></p><h1 id="the-proposed-sso-els-data-mining-algorithm">The Proposed SSO-ELS Data Mining Algorithm</h1><p>SSO-ELS:Simplified Swarm Optimization (SSO) with Exchange Local Search scheme.</p><h2 id="the-rule-mining-encoding">The rule mining encoding</h2><p><span class="math display">\[LowerBound=x-rand()*(max(X_i)-min(X_i))\quad (4)\]</span></p><p><span class="math display">\[UpperBound=x+rand()*(max(X_i)-min(X_i))\quad (5)\]</span></p><p><strong>$ (max(X_i ) − min(X_i ))$ is the range value of the data source in each attribute.???</strong></p><h2 id="rule-evaluation">Rule evaluation</h2><p>P,N: What's your judgement about the sample?</p><p>T,F: Is your judgement right(True) or not(False)?</p><div class="figure"><img src="/Assets/BlogImg/ROC1.png" alt="Confusion matrix"><p class="caption">Confusion matrix</p></div><p>Evaluation index:</p><p><img src="/Assets/BlogImg/ROC2.png" alt="evaluation index-w60"> <span class="math display">\[The \quad rule\quad quality = sensitivety\times specifigity=\frac{TP}{TP+FN}\times \frac{TN}{TN+FP}\]</span></p><h2 id="rule-pruning">Rule pruning</h2><p><span class="math display">\[Prediction\quad value +=a*rule\quad quality +\beta*percentage\quad of\quad the \quad rule \quad covered\]</span></p><h2 id="the-proposed-exchange-local-search-strategy">The proposed exchange local search strategy</h2><p>The principle of the ELS applied in SSO and PSO rule mining is to exchange the lower bound and upper bound value for one selected attribute from the neighbour particle, re-evaluate the fitness value of the target particle, and then try to find out the new <span class="math inline">\(pbest\)</span> of the target particle or new <span class="math inline">\(gbest\)</span> in the swarm.</p><p>Step 1 Pre-determine local search time <span class="math inline">\((T)\)</span> which will only be used for <span class="math inline">\(gbest\)</span>.</p><p>Step 2 Choose a target particle$ (P_t )$. In this phase, <span class="math inline">\(gbest\)</span> will be the first target particle to be run in <span class="math inline">\(T\)</span> times’ of local search. Later, the other <span class="math inline">\(pbest\)</span> will be sequentially selected as target particles and they will only be run once in local search.</p><p>Step 3 Randomly select one attribute from the rule set in the dataset. This process is called exchangeAttribute.</p><p>Step 4 Randomly select two different neighbour particles, <span class="math inline">\(P_x\)</span> and <span class="math inline">\(P_y\)</span> from the population.</p><p>Step 5 Get a <span class="math inline">\(LowerBound(x)\)</span> of the selected attribute (selected from Step 3) of $P_x $, and get an <span class="math inline">\(UpperBound(y)\)</span> of the selected attribute of <span class="math inline">\(P_y\)</span> .</p><p>Step 6 Temporarily replace the corresponding <span class="math inline">\(LowerBound\)</span> and <span class="math inline">\(UpperBound\)</span> of the tar- get particle with <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>.</p><p>Step 7 Re-evaluate the fitness value of the target particle.</p><p>Step 8 Check whether the fitness value is better than the current <span class="math inline">\(pbest\)</span> of the target particle or better than <span class="math inline">\(gbest\)</span>. If it is better, <span class="math inline">\(pbest\)</span> and <span class="math inline">\(gbest\)</span> will be updated,and the exchange value for the target particle will be kept; otherwise, the original <span class="math inline">\(LowerBound\)</span> and <span class="math inline">\(UpperBound\)</span> values will be positioned back to the target particle.</p><div class="figure"><img src="/Assets/BlogImg/ELS.png" alt="The process of the ELS"><p class="caption">The process of the ELS</p></div><div class="figure"><img src="/Assets/BlogImg/exchange%20Attribute.png" alt="The UpperBound and LowerBound exchange strategy for one selected attribute in each generation (note: UB = UpperBound, LB = LowerBound)"><p class="caption">The UpperBound and LowerBound exchange strategy for one selected attribute in each generation (note: UB = UpperBound, LB = LowerBound)</p></div><h1 id="conclusions">Conclusions</h1><p>The main idea of exchange local search is to improve and refine the searching process by exchanging the <span class="math inline">\(LowerBound\)</span> and <span class="math inline">\(UpperBound\)</span> for one selected attribute into the <span class="math inline">\(LowerBound\)</span> and <span class="math inline">\(UpperBound\)</span> of the corresponding target particle.</p><p>reference</p><p>precision and recall,ROC,AUC</p><p>https://towardsdatascience.com/beyond-accuracy-precision-and-recall-3da06bea9f6c</p><p>A new simplified swarm optimization (SSO) using exchange local search scheme</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;
&lt;p&gt;Swarm-based optimization tend to suffer from premature convergence in the high dimensional problem space. thus，proposing simplified swarm optimization (SSO) algorithm to overcome the above convergence problem by incorporating it with the new &lt;strong&gt;local search strategy&lt;/strong&gt; named ELS(Exchange Local Search).&lt;/p&gt;
&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;The ELS strategy is introduced to find a better solution from the neighbourhood of the current solution which is produced by SSO. It allows the particles to better explore the search space, and preserves swarm diversity which is important in preventing premature convergence of the particles.&lt;/p&gt;
    
    </summary>
    
      <category term="算法学习" scheme="//Rocky1ee.github.io/categories/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="智能算法" scheme="//Rocky1ee.github.io/tags/%E6%99%BA%E8%83%BD%E7%AE%97%E6%B3%95/"/>
    
      <category term="粒子群算法" scheme="//Rocky1ee.github.io/tags/%E7%B2%92%E5%AD%90%E7%BE%A4%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>粒子群算法</title>
    <link href="//Rocky1ee.github.io/2019/09/01/%E7%B2%92%E5%AD%90%E7%BE%A4%E7%AE%97%E6%B3%95PSO/"/>
    <id>//Rocky1ee.github.io/2019/09/01/粒子群算法PSO/</id>
    <published>2019-09-01T08:56:36.000Z</published>
    <updated>2019-12-10T07:45:55.605Z</updated>
    
    <content type="html"><![CDATA[<h1 id="算法思路">算法思路</h1><h2 id="基本思想">基本思想</h2><p>粒子群算法-particle swarm optimization。粒子群优化算法的基本思想是：通过群体中个体之间的协作和信息共享来寻找最优解。</p><p>我们可以设想这样的一个场景，一群鸟在随机搜寻食物。这个区域里只有一块食物。所有的鸟都不知道食物再哪里，但他们知道目前距离食物还有多远，那么找到食物的最佳策略是什么？</p><p><strong>1.找寻距离食物最近的鸟之周围区域</strong></p><p><strong>2.根据自己本身飞行的经验判断食物的所在</strong></p><p>在PSO中，每个优化问题的潜在解都可以想象成<span class="math inline">\(N\)</span>维搜索空间上的一个点，我们称之为“粒子”（Particle），由目标函数决定每个粒子的适应值，每个粒子还有一个速度决定他们运动的方向和距离，然后粒子们就追随当前的最优粒子在解空间中搜索。</p><h2 id="数学定义">数学定义</h2><p>粒子<span class="math inline">\(i\)</span>在<span class="math inline">\(N\)</span>维空间的位置为： <span class="math display">\[X_i = (x_1,x_2,...,x_N)\]</span> 运动速度表示为： <span class="math display">\[V_i=(v_1,v_2,...,v_N)\]</span> 每个粒子都有一个由目标函数决定的<strong>适应值</strong>，并且知道自己到目前为止的最好位置<span class="math inline">\((pbest_i)\)</span>和现在所在的位置<span class="math inline">\(X_i\)</span>．这个可以看作是粒子自己的运动经验。同时，每个粒子还知道到目前整个群体中位置最好的粒子<span class="math inline">\((gbest) (gbest是pbest_i中的最好值)\)</span>．这个可以看作是粒子同伴的经验。粒子就是通过自己的经验和同伴中最好的经验来决定下一步的运动。</p><a id="more"></a><h1 id="算法基本内容">算法基本内容</h1><h2 id="初始化">初始化</h2><p>对于每个粒子的位置<span class="math inline">\(X_i\)</span>和运动速度<span class="math inline">\(V_i\)</span>进行随机初始化</p><h2 id="更新">更新</h2><p>粒子速度的更新： <span class="math display">\[V_i = V_i+c_1\times rand()\times(pbest_i-X_i) + c_2\times rand()\times(gbest-X_i)\qquad公式(1)\]</span> 位置的更新： <span class="math display">\[X_i = X_i+V_i\qquad 公式(2)\]</span> 假设种群中粒子的总数为<span class="math inline">\(M\)</span>。<span class="math inline">\(i \in [1,M]\)</span>。</p><p>随机数<span class="math inline">\(rand() \in (0,1)\)</span>。</p><p>学习因子：<span class="math inline">\(c_1和c_2\)</span></p><p>假设空间的维度为<span class="math inline">\(N\)</span>,在每一维度上，<span class="math inline">\(v_d的上界为v_{dmax},d \in [1,N]\)</span></p><p>公式（1）的第一部分称为<strong>记忆项</strong>，表示上次速度大小和方向的影响；</p><p>第二部分称为<strong>自身认知项</strong>，是从当前点指向粒子自身最好点的一个矢量，粒子自身经验所决定的运动；</p><p>第三部分称为<strong>群体认知项</strong>，是从当前点指向种群最好点的矢量，反映了粒子间的协同合作。</p><p>粒子通过自身的经验和同伴中最好的经验来决定下一步的运动。</p><div class="figure"><img src="/Assets/BlogImg/粒子群算法1.png" alt="粒子群算法1"><p class="caption">粒子群算法1</p></div><h2 id="引入惯性权重因子">引入惯性权重因子</h2><p>为了完善算法引入惯性权重因子:<span class="math inline">\(\omega \geq 0\)</span>,公式(2)变为： <span class="math display">\[V_i = \omega \times V_i+c_1\times rand()\times(pbest_i-X_i) + c_2\times rand()\times(gbest-X_i)\qquad公式(3)\]</span> 当<span class="math inline">\(\omega\)</span>越大，越倾向于寻找全局最优。当<span class="math inline">\(\omega\)</span>越小越倾向于寻找局部最优。</p><h2 id="动态权重因子">动态权重因子</h2><p>试验发现动态权重因子比固定权重因子更有效。目前经常采用线性递减权值策略（linearly decreasing weight，LDW） <span class="math display">\[\omega=(\omega_{ini}-\omega_{end})(G_k-g)/G_k+\omega_{end}\]</span> <span class="math display">\[\omega_{ini}:初始惯性权值， \omega_{end}:迭代至最大数时惯性权值，G_k:最大迭代数， g:当前迭代数，\]</span></p><p>公式(3)被称为标准PSO。</p><h2 id="全局最优法">全局最优法</h2><p>当<span class="math inline">\(c_1=0\)</span>时，粒子没有了认知能力，变为<strong>只有社会的模型(social-only)</strong>： <span class="math display">\[V_i = \omega \times V_i + c_2\times rand()\times(gbest-X_i)\qquad公式(4)\]</span> 被称为<strong>全局PSO算法</strong>。粒子有扩展搜索空间能力，具有较快收敛速度，由于缺少局部搜索，对于复杂问题比标准PSO 更易陷入局部最优。</p><h2 id="局部最优法">局部最优法</h2><p>当<span class="math inline">\(c_2=0\)</span>时，则粒子之间没有社会信息，模型变为<strong>只有自我(cognition-only)模型</strong>： <span class="math display">\[V_i = \omega \times V_i+c_1\times rand()\times(pbest_i-X_i) \qquad公式(5)\]</span> 被称为<strong>局部PSO算法</strong>。由于个体之间没有信息的交流，整个群体相当于多个粒子进行盲目的随机搜索，收敛速度慢，因而得到最优解的可能性小。</p><h2 id="算法流程">算法流程</h2><div class="figure"><img src="/Assets/BlogImg/粒子群算法2.png" alt="粒子群算法2"><p class="caption">粒子群算法2</p></div><h1 id="实例应用">实例应用</h1><p>用粒子群算法求解<span class="math inline">\(y=f(x_1,x_2)=x_1^2+x_2^2,-10&lt;x_1,x_2&lt;10\)</span>的最小值。已知当<span class="math inline">\(x_1=x_2=0\)</span>时<span class="math inline">\(y\)</span>取最小值。现在用粒子群算法求解。</p><h2 id="初始化-1">初始化</h2><p>设种群大小<span class="math inline">\(M=3\)</span>;惯性权重<span class="math inline">\(\omega=0.5\)</span>;<span class="math inline">\(c_1=c_2=2\)</span>;<span class="math inline">\(r_1,r_2是[0,1]\)</span>内随机数。</p><p>假设个体的初始位置和速度分别为： <span class="math display">\[p_1=\begin{cases}v_1=(3,2)&amp;\\x_1=(8,-5)\end{cases}p_2=\begin{cases}v_1=(-3,-2)&amp;\\x_1=(-5,9)\end{cases}p_3=\begin{cases}v_1=(5,2)&amp;\\x_1=(-7,-8)\end{cases}\]</span> 计算适应函数值，并且得到粒子的历史最优位置和群体的全局最优位置 <span class="math display">\[\begin{cases}f_1=8^2+(-5)^2=89&amp;\\pbest=x_1=(8,-5)\end{cases}\begin{cases}f_2=(-5)^2+9^2=106&amp;\\pbest=x_2=(-5,9)\end{cases}\begin{cases}f_3=(-7)^2+(-8)^2=113&amp;\\pbest=x_3=(-7,-8)\end{cases}\]</span></p><p><span class="math display">\[gbest=pbest=(8,-5)\]</span></p><h2 id="粒子速度和位置更新">粒子速度和位置更新</h2><p><strong>根据自身的历史最优位置和全局最优位置，更新每个粒子的速度和位置：</strong> <span class="math display">\[p1=\begin{cases}V_1 = \omega \times V_1+c_1\times r_1\times(pbest_1-X_1) + c_2\times r_2\times(gbest-X_1)&amp;\\\Rightarrow v_1=\begin{cases}0.5\times3+0+0=1.5 &amp;\\0.5\times2+0+0=1\end{cases}&amp;\\x_1=x_1+v_1=(8,-5)+(1.5,1)=(9.5,-4)\end{cases}\]</span></p><p><span class="math display">\[p2=\begin{cases}V_2 = \omega \times V_2+c_1\times r_1\times(pbest_2-X_2) + c_2\times r_2\times(gbest-X_2)&amp;\\\Rightarrow v_2=\begin{cases}0.5\times-3+0+2\times0.3\times(8-(-5))=6.1 &amp;\\0.5\times2+0+2\times0.3\times(-5-9)=1.8\end{cases}&amp;\\x_2=x_2+v_2=(-5,9)+(6.1,1.8)=(1.1,10)\end{cases}\]</span></p><p><span class="math display">\[p3=\begin{cases}V_3 = \omega \times V_3+c_1\times r_1\times(pbest_3-X_3) + c_2\times r_2\times(gbest-X_3)&amp;\\\Rightarrow v_2=\begin{cases}0.5\times5+0+2\times0.3\times(8-(-7))=11.5 &amp;\\0.5\times3+0+2\times0.3\times(-5-(-8))=3.3\end{cases}&amp;\\x_3=x_3+v_3=(-7,-8)+(11.5,3.3)=(4.5,-4.7)\end{cases}\]</span></p><h2 id="更新粒子的历史最优位置和全局最优位置">更新粒子的历史最优位置和全局最优位置：</h2><p><span class="math display">\[f_1^*=9.5^2+(-4)^2=106.25&gt;f_1=89\\\begin{cases}f_1=89&amp;\\pbest_1=(8,-5)\end{cases}\]</span></p><p><span class="math display">\[f_2^*=1.1^2+10^2=101.21&lt;f_2=106\\\begin{cases}f_2=f_2^*=101.32&amp;\\pbest_2=(1.1,10)\end{cases}\]</span></p><p><span class="math display">\[f_3^*=4.5^2+(-4.7)^2=42.34&lt;f_3=113\\\begin{cases}f_3=f_3^*=42.34&amp;\\pbest_3=(4.5,-4.7)\end{cases}\]</span></p><p><span class="math display">\[gbest=pbest_3=(4.5,-4.7)\]</span></p><h2 id="迭代">迭代</h2><p>如果满足结束条件，则输出全局最优结果并结束程序，否则，转向第二步继续执行。</p><!-- more -->]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;算法思路&quot;&gt;算法思路&lt;/h1&gt;
&lt;h2 id=&quot;基本思想&quot;&gt;基本思想&lt;/h2&gt;
&lt;p&gt;粒子群算法-particle swarm optimization。粒子群优化算法的基本思想是：通过群体中个体之间的协作和信息共享来寻找最优解。&lt;/p&gt;
&lt;p&gt;我们可以设想这样的一个场景，一群鸟在随机搜寻食物。这个区域里只有一块食物。所有的鸟都不知道食物再哪里，但他们知道目前距离食物还有多远，那么找到食物的最佳策略是什么？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1.找寻距离食物最近的鸟之周围区域&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.根据自己本身飞行的经验判断食物的所在&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在PSO中，每个优化问题的潜在解都可以想象成&lt;span class=&quot;math inline&quot;&gt;\(N\)&lt;/span&gt;维搜索空间上的一个点，我们称之为“粒子”（Particle），由目标函数决定每个粒子的适应值，每个粒子还有一个速度决定他们运动的方向和距离，然后粒子们就追随当前的最优粒子在解空间中搜索。&lt;/p&gt;
&lt;h2 id=&quot;数学定义&quot;&gt;数学定义&lt;/h2&gt;
&lt;p&gt;粒子&lt;span class=&quot;math inline&quot;&gt;\(i\)&lt;/span&gt;在&lt;span class=&quot;math inline&quot;&gt;\(N\)&lt;/span&gt;维空间的位置为： &lt;span class=&quot;math display&quot;&gt;\[
X_i = (x_1,x_2,...,x_N)
\]&lt;/span&gt; 运动速度表示为： &lt;span class=&quot;math display&quot;&gt;\[
V_i=(v_1,v_2,...,v_N)
\]&lt;/span&gt; 每个粒子都有一个由目标函数决定的&lt;strong&gt;适应值&lt;/strong&gt;，并且知道自己到目前为止的最好位置&lt;span class=&quot;math inline&quot;&gt;\((pbest_i)\)&lt;/span&gt;和现在所在的位置&lt;span class=&quot;math inline&quot;&gt;\(X_i\)&lt;/span&gt;．这个可以看作是粒子自己的运动经验。同时，每个粒子还知道到目前整个群体中位置最好的粒子&lt;span class=&quot;math inline&quot;&gt;\((gbest) (gbest是pbest_i中的最好值)\)&lt;/span&gt;．这个可以看作是粒子同伴的经验。粒子就是通过自己的经验和同伴中最好的经验来决定下一步的运动。&lt;/p&gt;
    
    </summary>
    
      <category term="算法学习" scheme="//Rocky1ee.github.io/categories/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="智能算法" scheme="//Rocky1ee.github.io/tags/%E6%99%BA%E8%83%BD%E7%AE%97%E6%B3%95/"/>
    
      <category term="粒子群算法" scheme="//Rocky1ee.github.io/tags/%E7%B2%92%E5%AD%90%E7%BE%A4%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>蚁群算法</title>
    <link href="//Rocky1ee.github.io/2019/08/31/%E8%9A%81%E7%BE%A4%E7%AE%97%E6%B3%95(ACO)/"/>
    <id>//Rocky1ee.github.io/2019/08/31/蚁群算法(ACO)/</id>
    <published>2019-08-31T08:56:36.000Z</published>
    <updated>2019-12-10T07:45:43.146Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基本原理">基本原理</h1><div class="figure"><img src="/Assets/BlogImg/蚁群算法.png" alt="蚁群算法1"><p class="caption">蚁群算法1</p></div><div class="figure"><img src="/Assets/BlogImg/蚁群算法1.png" alt="蚁群算法2"><p class="caption">蚁群算法2</p></div><div class="figure"><img src="/Assets/BlogImg/蚁群算法2.png" alt="蚁群算法3"><p class="caption">蚁群算法3</p></div><a id="more"></a><h1 id="基本流程">基本流程</h1><h2 id="路径构建">路径构建</h2><p><span class="math display">\[\begin{equation}    P_{ij}(t) =   \begin{cases}   \frac{[\tau_{ij}(t)]^\alpha \times [\eta_{ij}(t)]^\beta}{\sum\limits_{k\in allowed_k }[\tau_{ik}(t)]^\alpha \times [\eta_{ik}(t)]^\beta}&amp;   {if \quad j \in allowed_k}\\   \qquad 0&amp;   others   \end{cases}  \end{equation}\]</span></p><hr><ul><li><span class="math inline">\(i,j\)</span>分别为起点和终点</li><li><span class="math inline">\(\eta_{ij} = \frac{1}{d_{ij}}\)</span>为能见度，是两点<span class="math inline">\(i、j\)</span>间的导数</li><li><span class="math inline">\(\tau_{ij}(t)\)</span>为时间<span class="math inline">\(t\)</span>时由<span class="math inline">\(i\)</span>到<span class="math inline">\(j\)</span>的信息素强度</li><li><span class="math inline">\(allowed_k\)</span>为从<span class="math inline">\(i\)</span>出发可访问到节点的集合</li><li><span class="math inline">\(\alpha,\beta\)</span>为两常数，分别是信息素和能见度的加权值</li></ul><p>结果表示<strong>当前点到每个可能的下个节点的概率</strong></p><h2 id="信息素更新">信息素更新</h2><p>蚂蚁的信息素释放量<span class="math inline">\(C(0)\)</span>,如果太小则容易导致局部最优。为什么？</p><p>如果太大，则对搜索方向的导向作用降低。一般用贪婪算法获取一个路径值<span class="math inline">\(Cnn\)</span>，然后根据蚂蚁个数来计算<span class="math inline">\(C(0) = m/Cnn\)</span>,<span class="math inline">\(m\)</span>为蚂蚁个数。</p><p>信息素更新如下：</p><p><span class="math display">\[\tau(t)=(1-p)\tau_{ij}+\sum_{k=1}^m\Delta\tau_{ij}^k\]</span> <span class="math inline">\(m\)</span>:蚂蚁个数，<span class="math inline">\(0&lt;\rho&lt;=1\)</span>:信息素蒸发率,<span class="math inline">\(\Delta\tau_{ij}^k\)</span>:第<span class="math inline">\(k\)</span>只蚂蚁在路径<span class="math inline">\(i\)</span>到 <span class="math inline">\(j\)</span> 所留下的信息素 <span class="math display">\[\begin{equation}    \Delta \tau_{ij}^k =   \begin{cases}   (c_k)^{-1}&amp;\quad 第k^{th}只蚂蚁经过路径(i，j)\\\\   0&amp;\quad others   \end{cases}  \end{equation}\]</span> 信息素挥发(evaporation):避免算法过快地向局部最优区域集中，有助于搜索区域的扩展。</p><p>信息素增强(reinforcement):指引最优路径的指南。</p><h2 id="迭代与停止">迭代与停止</h2><p>算法每次迭代：<strong>每次迭代的m只蚂蚁都完成了自己的路径过程，回到原点后的整个过程。</strong></p><p>停止：指定迭代次数或达成指定的最优解条件</p><h1 id="蚁群算法的实例">蚁群算法的实例</h1><div class="figure"><img src="/Assets/BlogImg/蚁群算法4.png" alt="蚁群算法4"><p class="caption">蚁群算法4</p></div><p>假设共<span class="math inline">\(m=3\)</span>只蚂蚁，参数<span class="math inline">\(\alpha=1,\beta=2,\rho=0.5\)</span></p><h2 id="初始化">初始化</h2><p>首先使用贪婪算法得到路径的<strong>(ACDBA)</strong>, 则<span class="math inline">\(C_{nn}=1+2+4+3=10\)</span>,求得<span class="math inline">\(\tau_0=m\div C_{nn}=0.3\)</span> <span class="math display">\[\tau(0)=\begin{bmatrix}0&amp;0.3&amp;0.3&amp;0.3 \\0.3&amp;0&amp;0.3&amp;0.3 \\0.3&amp;0.3&amp;0&amp;0.3 \\0.3&amp;0.3&amp;0.3&amp;0\end{bmatrix}\]</span></p><h2 id="出发地">出发地</h2><p>为每个蚂蚁随机选择出发城市，假设蚂蚁1选择城市A，蚂蚁2选择城市B，蚂蚁3选择城市D。</p><h2 id="访问地">访问地</h2><p>以蚂蚁1为例，当前城市<span class="math inline">\(i=A\)</span>,可访问城市集合<span class="math inline">\(J_1 (i)={B,C,D}\)</span></p><p>计算蚂蚁1访问各个城市的概率 <span class="math display">\[A \Rightarrow \begin{cases}B:\tau_{AB}^a\times\eta_{AB}^\beta=0.3^1\times\frac{1}{3}^2=0.033\\\\C:\tau_{AC}^a\times\eta_{AC}^\beta=0.3^1\times\frac{1}{1}^2=0.300\\\\D:\tau_{AD}^a\times\eta_{AD}^\beta=0.3^1\times\frac{1}{2}^2=0.075\\\\\end{cases}\]</span></p><p><span class="math display">\[P(B)=\frac{0.033}{0.033+0.3+0.075}=0.08 \\\\P(C)=\frac{0.03}{0.033+0.3+0.075}=0.74 \\\\P(D)=\frac{0.075}{0.033+0.3+0.075}=0.1\]</span></p><div class="figure"><img src="/Assets/BlogImg/轮盘赌选择法.jpeg" alt="轮盘赌选择法"><p class="caption">轮盘赌选择法</p></div><p>轮盘赌选择法：选择累积概率超过随机值的第一个个体。</p><p>用轮盘赌法选择下一个访问城市。假设产生的随机值<span class="math inline">\(r=0.05\)</span>，则蚂蚁<strong>1</strong>会选择城市<strong>B</strong> 同样，假设蚂蚁<strong>2</strong>选择城市<strong>D</strong>，蚂蚁<strong>3</strong>选择城市<strong>A</strong>。</p><p>现在蚂蚁<strong>1</strong>已经来到<strong>B</strong>了，路径记忆向量<span class="math inline">\(R^l=(AB)\)</span>,可访问城市集合<span class="math inline">\(J_i(i)={C,D}\)</span></p><p>蚂蚁<strong>1</strong>访问<strong>C，D</strong>城市的概率： <span class="math display">\[B\Rightarrow\begin{cases}C:\tau_{BC}^\alpha\times\eta_{BC}^\beta=0.3^1\times\frac{1}{5}^2=0.012\\\\D:\tau_{BD}^\alpha\times\eta_{BD}^\beta=0.3^1\times\frac{1}{4}^2=0.019\end{cases}\\\\P(C)=\frac{0.012}{0.012+0.019}=0.39\\\\P(D)=\frac{0.019}{0.012+0.019}=0.61\]</span> 用轮盘赌法选择下一个访问城市。假设产生的随机数<span class="math inline">\(r=0.67\)</span>，则蚂蚁<strong>1</strong>会选择城市<strong>D</strong> 同样，假设蚂蚁<strong>2</strong>选择城市<strong>C</strong>，蚂蚁<strong>3</strong>选择城市<strong>D</strong>。</p><p>最终，所有蚂蚁选择的路径为：</p><p>蚂蚁1：ABDCA</p><p>蚂蚁2：BDCAB</p><p>蚂蚁3：DACBD</p><h2 id="信息素更新-1">信息素更新</h2><p>每只蚂蚁走过的路径长度：<span class="math inline">\(C_1=3+4+2+1=10;C_2=4+2+1+3=10;C_3=2+1+5+4=12。\)</span></p><p>每条边信息素的更新如下: <span class="math display">\[\tau_{AB}=（1-\rho)\times\tau_{AB} + \sum_{k=1}^3\Delta\tau_{AB}^k=0.5\times0.3+(\frac{1}{10}+\frac{1}{10})=0.35\\\\\tau_{AC}=（1-\rho)\times\tau_{AC} + \sum_{k=1}^3\Delta\tau_{AC}^k=0.5\times0.3+(\frac{1}{12})=0.16\\\\\tau_{AD},\tau_{BC}...\]</span> 在<span class="math inline">\(\tau_{AB}\)</span>的计算中蚂蚁3并未走过路径<strong>AB</strong>，所以<span class="math inline">\(\tau_{AB}^3=0\)</span>。</p><h2 id="结束">结束</h2><p>如果满足结束条件，则输出全局最优结果并结束程序，否则，则转向步骤2继续执行。</p><p>references</p><p>https://www.cnblogs.com/asxinyu/p/Path_Optimization_Tsp_Problem_Ant_System_CSharp.html#opennewwindow</p><!-- more -->]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;基本原理&quot;&gt;基本原理&lt;/h1&gt;
&lt;div class=&quot;figure&quot;&gt;
&lt;img src=&quot;/Assets/BlogImg/蚁群算法.png&quot; alt=&quot;蚁群算法1&quot;&gt;
&lt;p class=&quot;caption&quot;&gt;蚁群算法1&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;figure&quot;&gt;
&lt;img src=&quot;/Assets/BlogImg/蚁群算法1.png&quot; alt=&quot;蚁群算法2&quot;&gt;
&lt;p class=&quot;caption&quot;&gt;蚁群算法2&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;figure&quot;&gt;
&lt;img src=&quot;/Assets/BlogImg/蚁群算法2.png&quot; alt=&quot;蚁群算法3&quot;&gt;
&lt;p class=&quot;caption&quot;&gt;蚁群算法3&lt;/p&gt;
&lt;/div&gt;
    
    </summary>
    
      <category term="算法学习" scheme="//Rocky1ee.github.io/categories/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="智能算法" scheme="//Rocky1ee.github.io/tags/%E6%99%BA%E8%83%BD%E7%AE%97%E6%B3%95/"/>
    
      <category term="蚁群算法" scheme="//Rocky1ee.github.io/tags/%E8%9A%81%E7%BE%A4%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
</feed>
