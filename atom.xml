<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Rocky1ee的博客</title>
  <icon>https://www.gravatar.com/avatar/cdf2628d43f941c34796949e0857e3a5</icon>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="//Rocky1ee.github.io/"/>
  <updated>2019-12-08T02:30:32.237Z</updated>
  <id>//Rocky1ee.github.io/</id>
  
  <author>
    <name>Rocky1ee</name>
    <email>666@qq.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>进化算法</title>
    <link href="//Rocky1ee.github.io/2019/09/11/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95GA/"/>
    <id>//Rocky1ee.github.io/2019/09/11/遗传算法GA/</id>
    <published>2019-09-11T05:56:36.000Z</published>
    <updated>2019-12-08T02:30:32.237Z</updated>
    
    <content type="html"><![CDATA[]]></content>
    
    <summary type="html">
    
      
      
        

      
    
    </summary>
    
      <category term="算法学习" scheme="//Rocky1ee.github.io/categories/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="智能算法" scheme="//Rocky1ee.github.io/tags/%E6%99%BA%E8%83%BD%E7%AE%97%E6%B3%95/"/>
    
      <category term="进化算法" scheme="//Rocky1ee.github.io/tags/%E8%BF%9B%E5%8C%96%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>粒子群算法</title>
    <link href="//Rocky1ee.github.io/2019/09/01/%E7%B2%92%E5%AD%90%E7%BE%A4%E7%AE%97%E6%B3%95PSO/"/>
    <id>//Rocky1ee.github.io/2019/09/01/粒子群算法PSO/</id>
    <published>2019-09-01T08:56:36.000Z</published>
    <updated>2019-12-07T13:43:03.399Z</updated>
    
    <content type="html"><![CDATA[<h1 id="算法思路">算法思路</h1><h2 id="基本思想">基本思想</h2><p>粒子群算法-particle swarm optimization。粒子群优化算法的基本思想是：通过群体中个体之间的协作和信息共享来寻找最优解。</p><p>我们可以设想这样的一个场景，一群鸟在随机搜寻食物。这个区域里只有一块食物。所有的鸟都不知道食物再哪里，但他们知道目前距离食物还有多远，那么找到食物的最佳策略是什么？</p><p><strong>1.找寻距离食物最近的鸟之周围区域</strong></p><p><strong>2.根据自己本身飞行的经验判断食物的所在</strong></p><p>在PSO中，每个优化问题的潜在解都可以想象成<span class="math inline">\(N\)</span>维搜索空间上的一个点，我们称之为“粒子”（Particle），由目标函数决定每个粒子的适应值，每个粒子还有一个速度决定他们运动的方向和距离，然后粒子们就追随当前的最优粒子在解空间中搜索。</p><h2 id="数学定义">数学定义</h2><p>粒子<span class="math inline">\(i\)</span>在<span class="math inline">\(N\)</span>维空间的位置为： <span class="math display">\[X_i = (x_1,x_2,...,x_N)\]</span> 运动速度表示为： <span class="math display">\[V_i=(v_1,v_2,...,v_N)\]</span> 每个粒子都有一个由目标函数决定的<strong>适应值</strong>，并且知道自己到目前为止的最好位置<span class="math inline">\((pbest_i)\)</span>和现在所在的位置<span class="math inline">\(X_i\)</span>．这个可以看作是粒子自己的运动经验。同时，每个粒子还知道到目前整个群体中位置最好的粒子<span class="math inline">\((gbest) (gbest是pbest_i中的最好值)\)</span>．这个可以看作是粒子同伴的经验。粒子就是通过自己的经验和同伴中最好的经验来决定下一步的运动。</p><h1 id="算法基本内容">算法基本内容</h1><h2 id="初始化">初始化</h2><p>对于每个粒子的位置<span class="math inline">\(X_i\)</span>和运动速度<span class="math inline">\(V_i\)</span>进行随机初始化</p><h2 id="更新">更新</h2><p>粒子速度的更新： <span class="math display">\[V_i = V_i+c_1\times rand()\times(pbest_i-X_i) + c_2\times rand()\times(gbest-X_i)\qquad公式(1)\]</span> 位置的更新： <span class="math display">\[X_i = X_i+V_i\qquad 公式(2)\]</span> 假设种群中粒子的总数为<span class="math inline">\(M\)</span>。<span class="math inline">\(i \in [1,M]\)</span>。</p><p>随机数<span class="math inline">\(rand() \in (0,1)\)</span>。</p><p>学习因子：<span class="math inline">\(c_1和c_2\)</span></p><p>假设空间的维度为<span class="math inline">\(N\)</span>,在每一维度上，<span class="math inline">\(v_d的上界为v_{dmax},d \in [1,N]\)</span></p><p>公式（1）的第一部分称为<strong>记忆项</strong>，表示上次速度大小和方向的影响；</p><p>第二部分称为<strong>自身认知项</strong>，是从当前点指向粒子自身最好点的一个矢量，粒子自身经验所决定的运动；</p><p>第三部分称为<strong>群体认知项</strong>，是从当前点指向种群最好点的矢量，反映了粒子间的协同合作。</p><p>粒子通过自身的经验和同伴中最好的经验来决定下一步的运动。</p><div class="figure"><img src="/Assets/BlogImg/粒子群算法1.png" alt="粒子群算法1"><p class="caption">粒子群算法1</p></div><h2 id="引入惯性权重因子">引入惯性权重因子</h2><p>为了完善算法引入惯性权重因子:<span class="math inline">\(\omega \geq 0\)</span>,公式(2)变为： <span class="math display">\[V_i = \omega \times V_i+c_1\times rand()\times(pbest_i-X_i) + c_2\times rand()\times(gbest-X_i)\qquad公式(3)\]</span> 当<span class="math inline">\(\omega\)</span>越大，越倾向于寻找全局最优。当<span class="math inline">\(\omega\)</span>越小越倾向于寻找局部最优。</p><h2 id="动态权重因子">动态权重因子</h2><p>试验发现动态权重因子比固定权重因子更有效。目前经常采用线性递减权值策略（linearly decreasing weight，LDW） <span class="math display">\[\omega=(\omega_{ini}-\omega_{end})(G_k-g)/G_k+\omega_{end}\]</span> <span class="math display">\[\omega_{ini}:初始惯性权值， \omega_{end}:迭代至最大数时惯性权值，G_k:最大迭代数， g:当前迭代数，\]</span></p><p>公式(3)被称为标准PSO。</p><h2 id="全局最优法">全局最优法</h2><p>当<span class="math inline">\(c_1=0\)</span>时，粒子没有了认知能力，变为<strong>只有社会的模型(social-only)</strong>： <span class="math display">\[V_i = \omega \times V_i + c_2\times rand()\times(gbest-X_i)\qquad公式(4)\]</span> 被称为<strong>全局PSO算法</strong>。粒子有扩展搜索空间能力，具有较快收敛速度，由于缺少局部搜索，对于复杂问题比标准PSO 更易陷入局部最优。</p><h2 id="局部最优法">局部最优法</h2><p>当<span class="math inline">\(c_2=0\)</span>时，则粒子之间没有社会信息，模型变为<strong>只有自我(cognition-only)模型</strong>： <span class="math display">\[V_i = \omega \times V_i+c_1\times rand()\times(pbest_i-X_i) \qquad公式(5)\]</span> 被称为<strong>局部PSO算法</strong>。由于个体之间没有信息的交流，整个群体相当于多个粒子进行盲目的随机搜索，收敛速度慢，因而得到最优解的可能性小。</p><h2 id="算法流程">算法流程</h2><div class="figure"><img src="/Assets/BlogImg/粒子群算法2.png" alt="粒子群算法2"><p class="caption">粒子群算法2</p></div><h1 id="实例应用">实例应用</h1><p>用粒子群算法求解<span class="math inline">\(y=f(x_1,x_2)=x_1^2+x_2^2,-10&lt;x_1,x_2&lt;10\)</span>的最小值。已知当<span class="math inline">\(x_1=x_2=0\)</span>时<span class="math inline">\(y\)</span>取最小值。现在用粒子群算法求解。</p><h2 id="初始化-1">初始化</h2><p>设种群大小<span class="math inline">\(M=3\)</span>;惯性权重<span class="math inline">\(\omega=0.5\)</span>;<span class="math inline">\(c_1=c_2=2\)</span>;<span class="math inline">\(r_1,r_2是[0,1]\)</span>内随机数。</p><p>假设个体的初始位置和速度分别为： <span class="math display">\[p_1=\begin{cases}v_1=(3,2)&amp;\\x_1=(8,-5)\end{cases}p_2=\begin{cases}v_1=(-3,-2)&amp;\\x_1=(-5,9)\end{cases}p_3=\begin{cases}v_1=(5,2)&amp;\\x_1=(-7,-8)\end{cases}\]</span> 计算适应函数值，并且得到粒子的历史最优位置和群体的全局最优位置 <span class="math display">\[\begin{cases}f_1=8^2+(-5)^2=89&amp;\\pbest=x_1=(8,-5)\end{cases}\begin{cases}f_2=(-5)^2+9^2=106&amp;\\pbest=x_2=(-5,9)\end{cases}\begin{cases}f_3=(-7)^2+(-8)^2=113&amp;\\pbest=x_3=(-7,-8)\end{cases}\]</span></p><p><span class="math display">\[gbest=pbest=(8,-5)\]</span></p><h2 id="粒子速度和位置更新">粒子速度和位置更新</h2><p><strong>根据自身的历史最优位置和全局最优位置，更新每个粒子的速度和位置：</strong> <span class="math display">\[p1=\begin{cases}V_1 = \omega \times V_1+c_1\times r_1\times(pbest_1-X_1) + c_2\times r_2\times(gbest-X_1)&amp;\\\Rightarrow v_1=\begin{cases}0.5\times3+0+0=1.5 &amp;\\0.5\times2+0+0=1\end{cases}&amp;\\x_1=x_1+v_1=(8,-5)+(1.5,1)=(9.5,-4)\end{cases}\]</span></p><p><span class="math display">\[p2=\begin{cases}V_2 = \omega \times V_2+c_1\times r_1\times(pbest_2-X_2) + c_2\times r_2\times(gbest-X_2)&amp;\\\Rightarrow v_2=\begin{cases}0.5\times-3+0+2\times0.3\times(8-(-5))=6.1 &amp;\\0.5\times2+0+2\times0.3\times(-5-9)=1.8\end{cases}&amp;\\x_2=x_2+v_2=(-5,9)+(6.1,1.8)=(1.1,10)\end{cases}\]</span></p><p><span class="math display">\[p3=\begin{cases}V_3 = \omega \times V_3+c_1\times r_1\times(pbest_3-X_3) + c_2\times r_2\times(gbest-X_3)&amp;\\\Rightarrow v_2=\begin{cases}0.5\times5+0+2\times0.3\times(8-(-7))=11.5 &amp;\\0.5\times3+0+2\times0.3\times(-5-(-8))=3.3\end{cases}&amp;\\x_3=x_3+v_3=(-7,-8)+(11.5,3.3)=(4.5,-4.7)\end{cases}\]</span></p><h2 id="更新粒子的历史最优位置和全局最优位置">更新粒子的历史最优位置和全局最优位置：</h2><p><span class="math display">\[f_1^*=9.5^2+(-4)^2=106.25&gt;f_1=89\\\begin{cases}f_1=89&amp;\\pbest_1=(8,-5)\end{cases}\]</span></p><p><span class="math display">\[f_2^*=1.1^2+10^2=101.21&lt;f_2=106\\\begin{cases}f_2=f_2^*=101.32&amp;\\pbest_2=(1.1,10)\end{cases}\]</span></p><p><span class="math display">\[f_3^*=4.5^2+(-4.7)^2=42.34&lt;f_3=113\\\begin{cases}f_3=f_3^*=42.34&amp;\\pbest_3=(4.5,-4.7)\end{cases}\]</span></p><p><span class="math display">\[gbest=pbest_3=(4.5,-4.7)\]</span></p><h2 id="迭代">迭代</h2><p>如果满足结束条件，则输出全局最优结果并结束程序，否则，转向第二步继续执行。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;算法思路&quot;&gt;算法思路&lt;/h1&gt;
&lt;h2 id=&quot;基本思想&quot;&gt;基本思想&lt;/h2&gt;
&lt;p&gt;粒子群算法-particle swarm optimization。粒子群优化算法的基本思想是：通过群体中个体之间的协作和信息共享来寻找最优解。&lt;/p&gt;
&lt;p&gt;我们可以设想
      
    
    </summary>
    
      <category term="算法学习" scheme="//Rocky1ee.github.io/categories/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="粒子群算法" scheme="//Rocky1ee.github.io/tags/%E7%B2%92%E5%AD%90%E7%BE%A4%E7%AE%97%E6%B3%95/"/>
    
      <category term="智能算法" scheme="//Rocky1ee.github.io/tags/%E6%99%BA%E8%83%BD%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>蚁群算法</title>
    <link href="//Rocky1ee.github.io/2019/08/31/%E8%9A%81%E7%BE%A4%E7%AE%97%E6%B3%95(ACO)/"/>
    <id>//Rocky1ee.github.io/2019/08/31/蚁群算法(ACO)/</id>
    <published>2019-08-31T08:56:36.000Z</published>
    <updated>2019-12-07T13:34:59.404Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基本原理">基本原理</h1><div class="figure"><img src="/Assets/BlogImg/蚁群算法.png" alt="蚁群算法1"><p class="caption">蚁群算法1</p></div><div class="figure"><img src="/Assets/BlogImg/蚁群算法1.png" alt="蚁群算法2"><p class="caption">蚁群算法2</p></div><div class="figure"><img src="/Assets/BlogImg/蚁群算法2.png" alt="蚁群算法3"><p class="caption">蚁群算法3</p></div><h1 id="基本流程">基本流程</h1><h2 id="路径构建">路径构建</h2><p><span class="math display">\[\begin{equation}    P_{ij}(t) =   \begin{cases}   \frac{[\tau_{ij}(t)]^\alpha \times [\eta_{ij}(t)]^\beta}{\sum\limits_{k\in allowed_k }[\tau_{ik}(t)]^\alpha \times [\eta_{ik}(t)]^\beta}&amp;   {if \quad j \in allowed_k}\\   \qquad 0&amp;   others   \end{cases}  \end{equation}\]</span></p><hr><ul><li><span class="math inline">\(i,j\)</span>分别为起点和终点</li><li><span class="math inline">\(\eta_{ij} = \frac{1}{d_{ij}}\)</span>为能见度，是两点<span class="math inline">\(i、j\)</span>间的导数</li><li><span class="math inline">\(\tau_{ij}(t)\)</span>为时间<span class="math inline">\(t\)</span>时由<span class="math inline">\(i\)</span>到<span class="math inline">\(j\)</span>的信息素强度</li><li><span class="math inline">\(allowed_k\)</span>为从<span class="math inline">\(i\)</span>出发可访问到节点的集合</li><li><span class="math inline">\(\alpha,\beta\)</span>为两常数，分别是信息素和能见度的加权值</li></ul><p>结果表示<strong>当前点到每个可能的下个节点的概率</strong></p><h2 id="信息素更新">信息素更新</h2><p>蚂蚁的信息素释放量<span class="math inline">\(C(0)\)</span>,如果太小则容易导致局部最优。为什么？</p><p>如果太大，则对搜索方向的导向作用降低。一般用贪婪算法获取一个路径值<span class="math inline">\(Cnn\)</span>，然后根据蚂蚁个数来计算<span class="math inline">\(C(0) = m/Cnn\)</span>,<span class="math inline">\(m\)</span>为蚂蚁个数。</p><p>信息素更新如下：</p><p><span class="math display">\[\tau(t)=(1-p)\tau_{ij}+\sum_{k=1}^m\Delta\tau_{ij}^k\]</span> <span class="math inline">\(m\)</span>:蚂蚁个数，<span class="math inline">\(0&lt;\rho&lt;=1\)</span>:信息素蒸发率,<span class="math inline">\(\Delta\tau_{ij}^k\)</span>:第<span class="math inline">\(k\)</span>只蚂蚁在路径<span class="math inline">\(i\)</span>到 <span class="math inline">\(j\)</span> 所留下的信息素 <span class="math display">\[\begin{equation}    \Delta \tau_{ij}^k =   \begin{cases}   (c_k)^{-1}&amp;\quad 第k^{th}只蚂蚁经过路径(i，j)\\\\   0&amp;\quad others   \end{cases}  \end{equation}\]</span> 信息素挥发(evaporation):避免算法过快地向局部最优区域集中，有助于搜索区域的扩展。</p><p>信息素增强(reinforcement):指引最优路径的指南。</p><h2 id="迭代与停止">迭代与停止</h2><p>算法每次迭代：<strong>每次迭代的m只蚂蚁都完成了自己的路径过程，回到原点后的整个过程。</strong></p><p>停止：指定迭代次数或达成指定的最优解条件</p><h1 id="蚁群算法的实例">蚁群算法的实例</h1><div class="figure"><img src="/Assets/BlogImg/蚁群算法4.png" alt="蚁群算法4"><p class="caption">蚁群算法4</p></div><p>假设共<span class="math inline">\(m=3\)</span>只蚂蚁，参数<span class="math inline">\(\alpha=1,\beta=2,\rho=0.5\)</span></p><h2 id="初始化">初始化</h2><p>首先使用贪婪算法得到路径的<strong>(ACDBA)</strong>, 则<span class="math inline">\(C_{nn}=1+2+4+3=10\)</span>,求得<span class="math inline">\(\tau_0=m\div C_{nn}=0.3\)</span> <span class="math display">\[\tau(0)=\begin{bmatrix}0&amp;0.3&amp;0.3&amp;0.3 \\0.3&amp;0&amp;0.3&amp;0.3 \\0.3&amp;0.3&amp;0&amp;0.3 \\0.3&amp;0.3&amp;0.3&amp;0\end{bmatrix}\]</span></p><h2 id="出发地">出发地</h2><p>为每个蚂蚁随机选择出发城市，假设蚂蚁1选择城市A，蚂蚁2选择城市B，蚂蚁3选择城市D。</p><h2 id="访问地">访问地</h2><p>以蚂蚁1为例，当前城市<span class="math inline">\(i=A\)</span>,可访问城市集合<span class="math inline">\(J_1 (i)={B,C,D}\)</span></p><p>计算蚂蚁1访问各个城市的概率 <span class="math display">\[A \Rightarrow \begin{cases}B:\tau_{AB}^a\times\eta_{AB}^\beta=0.3^1\times\frac{1}{3}^2=0.033\\\\C:\tau_{AC}^a\times\eta_{AC}^\beta=0.3^1\times\frac{1}{1}^2=0.300\\\\D:\tau_{AD}^a\times\eta_{AD}^\beta=0.3^1\times\frac{1}{2}^2=0.075\\\\\end{cases}\]</span></p><p><span class="math display">\[P(B)=\frac{0.033}{0.033+0.3+0.075}=0.08 \\\\P(C)=\frac{0.03}{0.033+0.3+0.075}=0.74 \\\\P(D)=\frac{0.075}{0.033+0.3+0.075}=0.1\]</span></p><div class="figure"><img src="/Assets/BlogImg/轮盘赌选择法.jpeg" alt="轮盘赌选择法"><p class="caption">轮盘赌选择法</p></div><p>轮盘赌选择法：选择累积概率超过随机值的第一个个体。</p><p>用轮盘赌法选择下一个访问城市。假设产生的随机值<span class="math inline">\(r=0.05\)</span>，则蚂蚁<strong>1</strong>会选择城市<strong>B</strong> 同样，假设蚂蚁<strong>2</strong>选择城市<strong>D</strong>，蚂蚁<strong>3</strong>选择城市<strong>A</strong>。</p><p>现在蚂蚁<strong>1</strong>已经来到<strong>B</strong>了，路径记忆向量<span class="math inline">\(R^l=(AB)\)</span>,可访问城市集合<span class="math inline">\(J_i(i)={C,D}\)</span></p><p>蚂蚁<strong>1</strong>访问<strong>C，D</strong>城市的概率： <span class="math display">\[B\Rightarrow\begin{cases}C:\tau_{BC}^\alpha\times\eta_{BC}^\beta=0.3^1\times\frac{1}{5}^2=0.012\\\\D:\tau_{BD}^\alpha\times\eta_{BD}^\beta=0.3^1\times\frac{1}{4}^2=0.019\end{cases}\\\\P(C)=\frac{0.012}{0.012+0.019}=0.39\\\\P(D)=\frac{0.019}{0.012+0.019}=0.61\]</span> 用轮盘赌法选择下一个访问城市。假设产生的随机数<span class="math inline">\(r=0.67\)</span>，则蚂蚁<strong>1</strong>会选择城市<strong>D</strong> 同样，假设蚂蚁<strong>2</strong>选择城市<strong>C</strong>，蚂蚁<strong>3</strong>选择城市<strong>D</strong>。</p><p>最终，所有蚂蚁选择的路径为：</p><p>蚂蚁1：ABDCA</p><p>蚂蚁2：BDCAB</p><p>蚂蚁3：DACBD</p><h2 id="信息素更新-1">信息素更新</h2><p>每只蚂蚁走过的路径长度：<span class="math inline">\(C_1=3+4+2+1=10;C_2=4+2+1+3=10;C_3=2+1+5+4=12。\)</span></p><p>每条边信息素的更新如下: <span class="math display">\[\tau_{AB}=（1-\rho)\times\tau_{AB} + \sum_{k=1}^3\Delta\tau_{AB}^k=0.5\times0.3+(\frac{1}{10}+\frac{1}{10})=0.35\\\\\tau_{AC}=（1-\rho)\times\tau_{AC} + \sum_{k=1}^3\Delta\tau_{AC}^k=0.5\times0.3+(\frac{1}{12})=0.16\\\\\tau_{AD},\tau_{BC}...\]</span> 在<span class="math inline">\(\tau_{AB}\)</span>的计算中蚂蚁3并未走过路径<strong>AB</strong>，所以<span class="math inline">\(\tau_{AB}^3=0\)</span>。</p><h2 id="结束">结束</h2><p>如果满足结束条件，则输出全局最优结果并结束程序，否则，则转向步骤2继续执行。</p><p>references</p><p>https://www.cnblogs.com/asxinyu/p/Path_Optimization_Tsp_Problem_Ant_System_CSharp.html#opennewwindow</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;基本原理&quot;&gt;基本原理&lt;/h1&gt;
&lt;div class=&quot;figure&quot;&gt;
&lt;img src=&quot;/Assets/BlogImg/蚁群算法.png&quot; alt=&quot;蚁群算法1&quot;&gt;
&lt;p class=&quot;caption&quot;&gt;蚁群算法1&lt;/p&gt;
&lt;/div&gt;
&lt;div 
      
    
    </summary>
    
      <category term="算法学习" scheme="//Rocky1ee.github.io/categories/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="智能算法" scheme="//Rocky1ee.github.io/tags/%E6%99%BA%E8%83%BD%E7%AE%97%E6%B3%95/"/>
    
      <category term="蚁群算法" scheme="//Rocky1ee.github.io/tags/%E8%9A%81%E7%BE%A4%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
</feed>
